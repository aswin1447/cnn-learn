{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# A bit of setup\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from classifiers.neural_net import TwoLayerNet\n",
    "from util.gradient_check import eval_numerical_gradient\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# toy data to verify the implementation\n",
    "\n",
    "input_size = 4\n",
    "hidden_size = 10\n",
    "num_classes = 3\n",
    "num_examples = 5\n",
    "\n",
    "def toy_model():\n",
    "    np.random.seed(0)\n",
    "    return TwoLayerNet(input_size, hidden_size, num_classes, std=1e-1)\n",
    "\n",
    "def toy_data():\n",
    "    np.random.seed(1)\n",
    "    X = 10 * np.random.randn(num_examples, input_size)\n",
    "    y = np.array([0, 1, 2, 2, 1])\n",
    "    # y = np.random.randint(num_classes, size=num_examples)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = toy_model()\n",
    "X, y = toy_data()\n",
    "# print(net.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foward pass: Scores & Loss\n",
    "Using weights and biases compute scores for all inputs and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.79856129989e-13\n",
      "3.68027207459e-08\n"
     ]
    }
   ],
   "source": [
    "def error(a, b):\n",
    "    print(np.sum(np.abs(a - b)))\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "scores = net.loss(X)\n",
    "correct_scores = np.asarray([\n",
    "  [-0.81233741, -1.27654624, -0.70335995],\n",
    "  [-0.17129677, -1.18803311, -0.47310444],\n",
    "  [-0.51590475, -1.01354314, -0.8504215 ],\n",
    "  [-0.15419291, -0.48629638, -0.52901952],\n",
    "  [-0.00618733, -0.12435261, -0.15226949]])\n",
    "\n",
    "loss, _ = net.loss(X, y, reg=0.1)\n",
    "correct_loss = 1.30378789133\n",
    "\n",
    "error(loss, correct_loss)\n",
    "error(scores, correct_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward pass: Gradients\n",
    "Use backprop to compute gradients on weights and biases of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 max relative error: 3.561318e-09\n",
      "b1 max relative error: 2.738421e-09\n",
      "b2 max relative error: 4.447646e-11\n",
      "W2 max relative error: 3.440708e-09\n"
     ]
    }
   ],
   "source": [
    "loss, grads = net.loss(X, y, reg=0.1)\n",
    "\n",
    "# these should all be less than 1e-8 or so\n",
    "for param_name in grads:\n",
    "    f = lambda W: net.loss(X, y, reg=0.1)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, net.params[param_name], verbose=False)\n",
    "    print('%s max relative error: %e' % (param_name, rel_error(param_grad_num, grads[param_name])))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
